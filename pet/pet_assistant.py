import streamlit as st
from zhipuai import ZhipuAI
import os
import base64
import tempfile
from dotenv import load_dotenv
import sounddevice as sd
import soundfile as sf
import numpy as np
from aip import AipSpeech  # ç™¾åº¦è¯­éŸ³è¯†åˆ«SDK

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
client = ZhipuAI(api_key=os.getenv("ZHIPU_API_KEY"))

# ç™¾åº¦è¯­éŸ³è¯†åˆ«é…ç½®
BAIDU_APP_ID = os.getenv("BAIDU_APP_ID")
BAIDU_API_KEY = os.getenv("BAIDU_API_KEY")
BAIDU_SECRET_KEY = os.getenv("BAIDU_SECRET_KEY")
baidu_client = AipSpeech(BAIDU_APP_ID, BAIDU_API_KEY, BAIDU_SECRET_KEY) if BAIDU_APP_ID and BAIDU_API_KEY and BAIDU_SECRET_KEY else None

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # å¯¹è¯å†å²
if "uploaded_image_base64" not in st.session_state:
    st.session_state.uploaded_image_base64 = None  # ä¸Šä¼ çš„å›¾ç‰‡

# ------------------------------
# æ ¸å¿ƒï¼šsounddeviceæœ¬åœ°å½•éŸ³ï¼ˆæ›¿ä»£webrtcï¼‰
# ------------------------------
def record_audio_with_sounddevice(duration=5, samplerate=16000):
    """
    ä½¿ç”¨sounddeviceæœ¬åœ°å½•éŸ³
    :param duration: å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
    :param samplerate: é‡‡æ ·ç‡ï¼ˆé€‚é…ç™¾åº¦æ¥å£ï¼‰
    :return: å½•éŸ³çš„WAVå­—èŠ‚æµ / None
    """
    try:
        st.info(f"ğŸ¤ å¼€å§‹å½•éŸ³ {duration} ç§’...è¯·å¯¹ç€éº¦å…‹é£è¯´è¯ï¼")
        # å¼€å§‹å½•éŸ³ï¼ˆé˜»å¡å¼ï¼Œå½•æ»¡æŒ‡å®šæ—¶é•¿ï¼‰
        audio_data = sd.rec(
            int(duration * samplerate),
            samplerate=samplerate,
            channels=1,  # å•å£°é“
            dtype='int16'  # 16bitæ ¼å¼ï¼ˆç™¾åº¦æ¥å£è¦æ±‚ï¼‰
        )
        sd.wait()  # ç­‰å¾…å½•éŸ³å®Œæˆ
        
        # å°†å½•éŸ³è½¬ä¸ºWAVå­—èŠ‚æµï¼ˆæ— éœ€ä¿å­˜æœ¬åœ°æ–‡ä»¶ï¼Œç›´æ¥å†…å­˜å¤„ç†ï¼‰
        wav_buffer = tempfile.SpooledTemporaryFile()
        sf.write(wav_buffer, audio_data, samplerate, format='WAV')
        wav_buffer.seek(0)
        wav_bytes = wav_buffer.read()
        wav_buffer.close()
        
        st.success("âœ… å½•éŸ³å®Œæˆï¼æ­£åœ¨è¯†åˆ«è¯­éŸ³å†…å®¹...")
        return wav_bytes
    except Exception as e:
        st.error(f"âŒ å½•éŸ³å¤±è´¥ï¼š{str(e)}")
        st.info("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦æ­£å¸¸ï¼Œæˆ–é‡æ–°å®‰è£…sounddeviceï¼ˆpip install sounddevice --upgradeï¼‰")
        return None

# ------------------------------
# ç™¾åº¦è¯­éŸ³è¯†åˆ«ï¼ˆé€‚é…sounddeviceå½•éŸ³ï¼‰
# ------------------------------
def baidu_speech_to_text(wav_bytes):
    """å°†sounddeviceå½•åˆ¶çš„WAVå­—èŠ‚æµè½¬ä¸ºæ–‡å­—"""
    if not baidu_client:
        st.error("âŒ æœªé…ç½®ç™¾åº¦è¯­éŸ³å‚æ•°ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­å¡«å†™BAIDU_APP_ID/API_KEY/SECRET_KEY")
        return ""
    
    try:
        # æå–WAVçš„çº¯éŸ³é¢‘æ•°æ®ï¼ˆå»æ‰44å­—èŠ‚æ–‡ä»¶å¤´ï¼Œé€‚é…ç™¾åº¦PCMæ ¼å¼ï¼‰
        pcm_data = wav_bytes[44:] if len(wav_bytes) > 44 else wav_bytes
        
        # è°ƒç”¨ç™¾åº¦çŸ­è¯­éŸ³è¯†åˆ«æ¥å£
        result = baidu_client.asr(pcm_data, 'pcm', 16000, {
            'dev_pid': 1537,  # æ™®é€šè¯è¯†åˆ«
        })
        
        # è§£æç»“æœ
        if result.get("err_no") == 0 and "result" in result and len(result["result"]) > 0:
            return result["result"][0]
        elif result.get("err_no") == 3301:
            st.warning("âš ï¸ å½•éŸ³ä¸­æœªæ£€æµ‹åˆ°æœ‰æ•ˆå£°éŸ³ï¼Œè¯·é è¿‘éº¦å…‹é£å¹¶æé«˜éŸ³é‡")
        else:
            st.error(f"âŒ è¯†åˆ«å¤±è´¥ï¼š{result.get('err_msg', 'æœªçŸ¥é”™è¯¯')}ï¼ˆé”™è¯¯ç ï¼š{result.get('err_no')}ï¼‰")
        return ""
    except Exception as e:
        st.error(f"âŒ è°ƒç”¨ç™¾åº¦æ¥å£å‡ºé”™ï¼š{str(e)}")
        return ""

# ------------------------------
# æ™ºè°±AIæ ¸å¿ƒåŠŸèƒ½ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
# ------------------------------
def pet_multimodal_chat(image_base64, user_input, chat_history):
    context = "\n".join([f"{item['role']}: {item['content']}" for item in chat_history])
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": f"""
                    ä½ æ˜¯ä¸“ä¸šçš„å® ç‰©åŒ»ç”ŸåŠ©æ‰‹ï¼Œç»“åˆå†å²å¯¹è¯ã€å½“å‰å›¾ç‰‡å’Œç”¨æˆ·é—®é¢˜ï¼Œå›ç­”ç®€æ´ç²¾å‡†ï¼š
                    å†å²å¯¹è¯ï¼š{context}
                    ç”¨æˆ·é—®é¢˜ï¼š{user_input}
                """},
                {"type": "image_url", "image_url": {"url": image_base64}}
            ]
        }
    ]
    try:
        response = client.chat.completions.create(model="glm-4v", messages=messages, temperature=0.3)
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"âŒ å¤šæ¨¡æ€è¯·æ±‚å‡ºé”™ï¼š{str(e)}")
        return "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å¤„ç†å›¾ç‰‡è¯·æ±‚ï¼Œè¯·ç¨åå†è¯•ã€‚"

def pet_text_chat(user_input, chat_history):
    context = "\n".join([f"{item['role']}: {item['content']}" for item in chat_history])
    prompt = f"""
        ä½ æ˜¯ä¸“ä¸šçš„å® ç‰©å…»æŠ¤åŠ©æ‰‹ï¼Œç»“åˆå†å²å¯¹è¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œè¦ä¸ªæ€§åŒ–ï¼š
        å†å²å¯¹è¯ï¼š{context}
        ç”¨æˆ·é—®é¢˜ï¼š{user_input}
    """
    try:
        response = client.chat.completions.create(model="glm-4", messages=[{"role": "user", "content": prompt}], temperature=0.3)
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"âŒ æ–‡æœ¬è¯·æ±‚å‡ºé”™ï¼š{str(e)}")
        return "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å¤„ç†è¯·æ±‚ï¼Œè¯·ç¨åå†è¯•ã€‚"

# ------------------------------
# ç•Œé¢å¸ƒå±€ï¼ˆæ ¸å¿ƒï¼šsounddeviceå½•éŸ³æ¨¡å—ï¼‰
# ------------------------------
st.title("ğŸ¾ å® ç‰©è¯†åˆ«ä¸å…»æŠ¤åŠ©æ‰‹ | æœ¬åœ°å½•éŸ³ç‰ˆ")
st.caption("ï¼ˆå¤§äºŒä½œä¸š Â· sounddeviceå½•éŸ³ + æ™ºè°±AI + ç™¾åº¦è¯­éŸ³è¯†åˆ«ï¼‰")

# ä¾§è¾¹æ åŠŸèƒ½åŒº
with st.sidebar:
    # ç™¾åº¦è¯­éŸ³çŠ¶æ€æç¤º
    if baidu_client:
        st.success("âœ… å·²è¿æ¥ç™¾åº¦è¯­éŸ³è¯†åˆ«æœåŠ¡")
    else:
        st.error("âŒ æœªé…ç½®ç™¾åº¦è¯­éŸ³å‚æ•°")
    
    # 1. å›¾ç‰‡ä¸Šä¼ 
    st.subheader("ğŸ“· ä¸Šä¼ å® ç‰©ç…§ç‰‡")
    uploaded_image = st.file_uploader("é€‰æ‹©ç…§ç‰‡ï¼ˆjpg/pngï¼‰", type=["jpg", "png", "jpeg"])
    if uploaded_image:
        image_base64 = base64.b64encode(uploaded_image.getvalue()).decode("utf-8")
        st.session_state.uploaded_image_base64 = f"data:image/jpeg;base64,{image_base64}"
        st.image(uploaded_image, caption="å·²ä¸Šä¼ çš„å® ç‰©ç…§ç‰‡", use_column_width=True)
    
    st.divider()
    
    # 2. sounddeviceæœ¬åœ°å½•éŸ³æ¨¡å—ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰
    st.subheader("ğŸ¤ æœ¬åœ°è¯­éŸ³æé—®ï¼ˆæ— æµè§ˆå™¨ä¾èµ–ï¼‰")
    st.info("ğŸ’¡ æ“ä½œæµç¨‹ï¼šè¾“å…¥å½•éŸ³æ—¶é•¿ â†’ ç‚¹å‡»å½•éŸ³ â†’ è¯´è¯ â†’ è‡ªåŠ¨è¯†åˆ« â†’ AIå›å¤")
    
    # å½•éŸ³æ—¶é•¿è¾“å…¥ï¼ˆé»˜è®¤5ç§’ï¼Œå¯è‡ªå®šä¹‰ï¼‰
    record_duration = st.number_input(
        "å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰",
        min_value=1, max_value=10, value=5, step=1,
        help="å»ºè®®3-5ç§’ï¼Œè¿‡é•¿å¯èƒ½è¯†åˆ«ä¸å‡†ç¡®"
    )
    
    # å¼€å§‹å½•éŸ³æŒ‰é’®
    if st.button("â–¶ï¸ å¼€å§‹å½•éŸ³å¹¶è¯†åˆ«", type="primary"):
        # ç¬¬ä¸€æ­¥ï¼šæœ¬åœ°å½•éŸ³
        wav_bytes = record_audio_with_sounddevice(duration=record_duration)
        if not wav_bytes:
            st.stop()
        
        # ç¬¬äºŒæ­¥ï¼šè°ƒç”¨ç™¾åº¦è¯†åˆ«
        recognized_text = baidu_speech_to_text(wav_bytes)
        if not recognized_text:
            st.stop()
        
        # ç¬¬ä¸‰æ­¥ï¼šè¯†åˆ«æˆåŠŸï¼Œè‡ªåŠ¨æäº¤åˆ°èŠå¤©æ¡†
        st.success(f"âœ… è¯­éŸ³è¯†åˆ«ç»“æœï¼š{recognized_text}")
        user_prompt = recognized_text
        
        # å±•ç¤ºç”¨æˆ·è¾“å…¥
        with st.chat_message("user"):
            st.markdown(user_prompt)
        st.session_state.chat_history.append({"role": "user", "content": user_prompt})
        
        # è°ƒç”¨æ™ºè°±AIç”Ÿæˆå›å¤
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” æ­£åœ¨ç”Ÿæˆå›å¤..."):
                if st.session_state.uploaded_image_base64:
                    response = pet_multimodal_chat(st.session_state.uploaded_image_base64, user_prompt, st.session_state.chat_history)
                else:
                    response = pet_text_chat(user_prompt, st.session_state.chat_history)
            st.markdown(response)
        st.session_state.chat_history.append({"role": "assistant", "content": response})
    
    st.divider()
    
    # 3. åŠŸèƒ½æŒ‰é’®
    if st.button("â¹ï¸ ç»“æŸé¡¹ç›®", type="primary"):
        st.warning("âš ï¸ é¡¹ç›®å·²åœæ­¢è¿è¡Œï¼")
        st.info("âœ… è¯·åœ¨ç»ˆç«¯æŒ‰ Ctrl + C å½»åº•å…³é—­æœåŠ¡")
        st.stop()
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
        st.session_state.chat_history = []
        st.session_state.uploaded_image_base64 = None
        st.rerun()

# ------------------------------
# èŠå¤©ç•Œé¢ï¼ˆä¿ç•™æ–‡å­—è¾“å…¥ï¼‰
# ------------------------------
# æ¸²æŸ“å†å²å¯¹è¯
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# æ–‡å­—è¾“å…¥æ¡†
user_prompt = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆå¦‚ï¼šå®ƒä¸€ç›´æŒ è€³æœµæ€ä¹ˆåŠï¼Ÿï¼‰")
if user_prompt:
    with st.chat_message("user"):
        st.markdown(user_prompt)
    st.session_state.chat_history.append({"role": "user", "content": user_prompt})
    
    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨æ€è€ƒå›å¤..."):
            if st.session_state.uploaded_image_base64:
                response = pet_multimodal_chat(st.session_state.uploaded_image_base64, user_prompt, st.session_state.chat_history)
            else:
                response = pet_text_chat(user_prompt, st.session_state.chat_history)
        st.markdown(response)
    st.session_state.chat_history.append({"role": "assistant", "content": response})